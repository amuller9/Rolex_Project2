{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Real or Not? NLP with Disaster Tweets - Project 2 - Sam's part"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Big-Scale Analytics - Project 2 - Team Rolex\n",
        "> Samuel Lew, Alexandre Lang, Samy Bouzerda, Alix Muller"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-05-12T20:25:02.031Z",
          "iopub.execute_input": "2020-05-12T20:25:02.065Z",
          "shell.execute_reply": "2020-05-12T20:25:03.853Z",
          "iopub.status.idle": "2020-05-12T20:25:03.831Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv ('../data/train.csv')\n",
        "train = train[['id', 'text', 'target']]\n",
        "\n",
        "test = pd.read_csv ('../data/test.csv')\n",
        "test = test[['id', 'text']]\n",
        "\n",
        "train.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": [
              "   id                                               text  target\n",
              "0   1  Our Deeds are the Reason of this #earthquake M...       1\n",
              "1   4             Forest fire near La Ronge Sask. Canada       1\n",
              "2   5  All residents asked to 'shelter in place' are ...       1\n",
              "3   6  13,000 people receive #wildfires evacuation or...       1\n",
              "4   7  Just got sent this photo from Ruby #Alaska as ...       1"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:25:15.101Z",
          "iopub.execute_input": "2020-05-12T20:25:15.128Z",
          "iopub.status.idle": "2020-05-12T20:25:15.214Z",
          "shell.execute_reply": "2020-05-12T20:25:15.504Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_count = 0\n",
        "for row in train.iterrows():\n",
        "  total_count += 1\n",
        "print(f'there are {total_count} tweets in the dataset')\n",
        "\n",
        "train_yes = train.query('target == 1')\n",
        "yes_count = 0\n",
        "for row in train_yes.iterrows():\n",
        "    yes_count += 1\n",
        "print(f'there are {yes_count} tweets about disasters')\n",
        "\n",
        "train_no = train.query('target == 0')\n",
        "no_count = 0\n",
        "for row in train_no.iterrows():\n",
        "    no_count += 1\n",
        "print(f'there are {no_count} tweets that are not about disasters')\n",
        "\n",
        "print('the classification base rate is ' + str(yes_count/(yes_count+no_count)*100)[:5] + '%')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there are 7613 tweets in the dataset\n",
            "there are 3271 tweets about disasters\n",
            "there are 4342 tweets that are not about disasters\n",
            "the classification base rate is 42.96%\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:25:16.187Z",
          "iopub.execute_input": "2020-05-12T20:25:16.228Z",
          "iopub.status.idle": "2020-05-12T20:25:18.889Z",
          "shell.execute_reply": "2020-05-12T20:25:19.221Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text processing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install spacy\n",
        "#!python -m spacy download en"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:25:18.925Z",
          "iopub.execute_input": "2020-05-12T20:25:18.948Z",
          "shell.execute_reply": "2020-05-12T20:25:19.242Z",
          "iopub.status.idle": "2020-05-12T20:25:18.991Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import spacy\n",
        "import re\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "parser = English()\n",
        "nlp = spacy.load('en')\n",
        "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "punctuations = string.punctuation\n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:25:19.040Z",
          "iopub.execute_input": "2020-05-12T20:25:19.059Z",
          "iopub.status.idle": "2020-05-12T20:25:26.277Z",
          "shell.execute_reply": "2020-05-12T20:25:26.302Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lowercase and remove punctuation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    \n",
        "    return text\n",
        "  \n",
        "  \n",
        "train['filtered_tweet'] = train['text'].apply(lambda x: clean_text(x))\n",
        "test['filtered_tweet'] = test['text'].apply(lambda x: clean_text(x))\n",
        "\n",
        "train.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": [
              "   id                                               text  target  \\\n",
              "0   1  Our Deeds are the Reason of this #earthquake M...       1   \n",
              "1   4             Forest fire near La Ronge Sask. Canada       1   \n",
              "2   5  All residents asked to 'shelter in place' are ...       1   \n",
              "3   6  13,000 people receive #wildfires evacuation or...       1   \n",
              "4   7  Just got sent this photo from Ruby #Alaska as ...       1   \n",
              "\n",
              "                                      filtered_tweet  \n",
              "0  our deeds are the reason of this earthquake ma...  \n",
              "1              forest fire near la ronge sask canada  \n",
              "2  all residents asked to shelter in place are be...  \n",
              "3   people receive wildfires evacuation orders in...  \n",
              "4  just got sent this photo from ruby alaska as s...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>filtered_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "      <td>our deeds are the reason of this earthquake ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>all residents asked to shelter in place are be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "      <td>people receive wildfires evacuation orders in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>just got sent this photo from ruby alaska as s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:25:26.410Z",
          "iopub.execute_input": "2020-05-12T20:25:26.442Z",
          "iopub.status.idle": "2020-05-12T20:25:27.038Z",
          "shell.execute_reply": "2020-05-12T20:25:27.130Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize tweets"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "\n",
        "train['filtered_tweet'] = train['filtered_tweet'].apply(lambda x: tokenizer.tokenize(x))\n",
        "\n",
        "test['filtered_tweet'] = test['filtered_tweet'].apply(lambda x: tokenizer.tokenize(x))\n",
        "\n",
        "train.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": [
              "   id                                               text  target  \\\n",
              "0   1  Our Deeds are the Reason of this #earthquake M...       1   \n",
              "1   4             Forest fire near La Ronge Sask. Canada       1   \n",
              "2   5  All residents asked to 'shelter in place' are ...       1   \n",
              "3   6  13,000 people receive #wildfires evacuation or...       1   \n",
              "4   7  Just got sent this photo from Ruby #Alaska as ...       1   \n",
              "\n",
              "                                      filtered_tweet  \n",
              "0  [our, deeds, are, the, reason, of, this, earth...  \n",
              "1      [forest, fire, near, la, ronge, sask, canada]  \n",
              "2  [all, residents, asked, to, shelter, in, place...  \n",
              "3  [people, receive, wildfires, evacuation, order...  \n",
              "4  [just, got, sent, this, photo, from, ruby, ala...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>filtered_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "      <td>[people, receive, wildfires, evacuation, order...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:25:27.061Z",
          "iopub.execute_input": "2020-05-12T20:25:27.079Z",
          "iopub.status.idle": "2020-05-12T20:25:27.188Z",
          "shell.execute_reply": "2020-05-12T20:25:27.278Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove stopwords and punctuation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove stopwords and punctuation\n",
        "def remove_stopwords(text):\n",
        "    text = [word for word in text if word not in stopwords.words('english')]\n",
        "    text = [word for word in text if word not in punctuations]\n",
        "    \n",
        "    return text\n",
        "\n",
        "train['filtered_tweet'] = train['filtered_tweet'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "test['filtered_tweet'] = test['filtered_tweet'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "train.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": [
              "   id                                               text  target  \\\n",
              "0   1  Our Deeds are the Reason of this #earthquake M...       1   \n",
              "1   4             Forest fire near La Ronge Sask. Canada       1   \n",
              "2   5  All residents asked to 'shelter in place' are ...       1   \n",
              "3   6  13,000 people receive #wildfires evacuation or...       1   \n",
              "4   7  Just got sent this photo from Ruby #Alaska as ...       1   \n",
              "\n",
              "                                      filtered_tweet  \n",
              "0  [deeds, reason, earthquake, may, allah, forgiv...  \n",
              "1      [forest, fire, near, la, ronge, sask, canada]  \n",
              "2  [residents, asked, shelter, place, notified, o...  \n",
              "3  [people, receive, wildfires, evacuation, order...  \n",
              "4  [got, sent, photo, ruby, alaska, smoke, wildfi...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>filtered_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "      <td>[deeds, reason, earthquake, may, allah, forgiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[residents, asked, shelter, place, notified, o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "      <td>[people, receive, wildfires, evacuation, order...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:25:27.214Z",
          "iopub.execute_input": "2020-05-12T20:25:27.230Z",
          "iopub.status.idle": "2020-05-12T20:25:59.028Z",
          "shell.execute_reply": "2020-05-12T20:25:59.478Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recreate sentences"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence(text):\n",
        "  sentence = ''\n",
        "  for word in text:\n",
        "    sentence = sentence + ' ' + word\n",
        "  \n",
        "  return sentence\n",
        "\n",
        "train['filtered_tweet'] = train['filtered_tweet'].apply(lambda x: sentence(x))\n",
        "\n",
        "test['filtered_tweet'] = test['filtered_tweet'].apply(lambda x: sentence(x))\n",
        "\n",
        "train.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": [
              "   id                                               text  target  \\\n",
              "0   1  Our Deeds are the Reason of this #earthquake M...       1   \n",
              "1   4             Forest fire near La Ronge Sask. Canada       1   \n",
              "2   5  All residents asked to 'shelter in place' are ...       1   \n",
              "3   6  13,000 people receive #wildfires evacuation or...       1   \n",
              "4   7  Just got sent this photo from Ruby #Alaska as ...       1   \n",
              "\n",
              "                                      filtered_tweet  \n",
              "0       deeds reason earthquake may allah forgive us  \n",
              "1              forest fire near la ronge sask canada  \n",
              "2   residents asked shelter place notified office...  \n",
              "3   people receive wildfires evacuation orders ca...  \n",
              "4   got sent photo ruby alaska smoke wildfires po...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>filtered_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "      <td>deeds reason earthquake may allah forgive us</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>residents asked shelter place notified office...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "      <td>people receive wildfires evacuation orders ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>got sent photo ruby alaska smoke wildfires po...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:25:59.061Z",
          "iopub.execute_input": "2020-05-12T20:25:59.086Z",
          "iopub.status.idle": "2020-05-12T20:25:59.132Z",
          "shell.execute_reply": "2020-05-12T20:25:59.496Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification models"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic regression"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!python -m spacy download en_core_web_sm\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:25:59.167Z",
          "iopub.execute_input": "2020-05-12T20:25:59.190Z",
          "iopub.status.idle": "2020-05-12T20:25:59.218Z",
          "shell.execute_reply": "2020-05-12T20:25:59.514Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize tweets"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def spacy_tokenizer(sentence):\n",
        "    mytokens = parser(sentence)\n",
        "    mytokens = [ word.lemma_.lower().strip() \n",
        "                if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "    mytokens = [ word for word in mytokens \n",
        "                if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    return mytokens\n",
        "\n",
        "\n",
        "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:25:59.247Z",
          "iopub.execute_input": "2020-05-12T20:25:59.263Z",
          "iopub.status.idle": "2020-05-12T20:25:59.295Z",
          "shell.execute_reply": "2020-05-12T20:25:59.524Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split train/test sets (from train dataset)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train['filtered_tweet']\n",
        "y = train['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=72)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:25:59.333Z",
          "iopub.execute_input": "2020-05-12T20:25:59.352Z",
          "iopub.status.idle": "2020-05-12T20:25:59.381Z",
          "shell.execute_reply": "2020-05-12T20:25:59.531Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run logistic regression"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression(solver=\"lbfgs\")\n",
        "\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "predicted = pipe.predict(X_test)\n",
        "\n",
        "accuracy = metrics.accuracy_score(y_test, predicted)\n",
        "precision = metrics.precision_score(y_test, predicted, average=None)\n",
        "recall = metrics.recall_score(y_test, predicted, average=None)\n",
        "\n",
        "print(accuracy)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8069176882661997\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:25:59.409Z",
          "iopub.execute_input": "2020-05-12T20:25:59.428Z",
          "shell.execute_reply": "2020-05-12T20:26:01.454Z",
          "iopub.status.idle": "2020-05-12T20:26:01.270Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'For a train/test split treshold of 0.3: \\n')\n",
        "\n",
        "print(f'We can see here that our model identified a tweet about a disaster {str(accuracy*100)[:4]}% of the time. \\n')\n",
        "\n",
        "print(f'When it predicted a tweet to be about a disaster, it was correctly assessed {str(precision[0]*100)[:4]}% of the time, \\nand was correctly assessed for a tweet not about a disaster {str(precision[1]*100)[:4]}% of the time. \\n')\n",
        "\n",
        "print(f'When given a tweet about a disaster, the model considered it as being about a disaster {str(recall[0]*100)[:4]}% of the time, \\nand when given a tweet not about a disaster the model considered it as not a disaster for {str(recall[1]*100)[:4]}% of the time. \\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For a train/test split treshold of 0.3: \n",
            "\n",
            "We can see here that our model identified a tweet about a disaster 80.6% of the time. \n",
            "\n",
            "When it predicted a tweet to be about a disaster, it was correctly assessed 77.9% of the time, \n",
            "and was correctly assessed for a tweet not about a disaster 86.1% of the time. \n",
            "\n",
            "When given a tweet about a disaster, the model considered it as being about a disaster 91.7% of the time, \n",
            "and when given a tweet not about a disaster the model considered it as not a disaster for 66.3% of the time. \n",
            "\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:26:01.301Z",
          "iopub.execute_input": "2020-05-12T20:26:01.320Z",
          "iopub.status.idle": "2020-05-12T20:26:01.358Z",
          "shell.execute_reply": "2020-05-12T20:26:01.472Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the results for different levels of train/test split treshold"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = train['filtered_tweet']\n",
        "y = train['target']\n",
        "\n",
        "data_acc = {}\n",
        "data_prec = {}\n",
        "data_rec = {}\n",
        "\n",
        "\n",
        "for i in range(1, 100, 1):\n",
        "  j = i/100\n",
        "  \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=j, random_state=72)\n",
        "  \n",
        "  pipe.fit(X_train, y_train)\n",
        "\n",
        "  predicted = pipe.predict(X_test)\n",
        "\n",
        "  accuracy = metrics.accuracy_score(y_test, predicted)\n",
        "  precision = metrics.precision_score(y_test, predicted, average=None)\n",
        "  recall = metrics.recall_score(y_test, predicted, average=None)\n",
        "  \n",
        "  data_acc[j] = accuracy\n",
        "  data_prec[j] = precision\n",
        "  data_rec[j] = recall\n",
        "  \n",
        "names_acc = list(data_acc.keys())\n",
        "values_acc = list(data_acc.values())\n",
        "\n",
        "names_prec = list(data_prec.keys())\n",
        "values_prec = list(data_prec.values())\n",
        "\n",
        "names_rec = list(data_rec.keys())\n",
        "values_rec = list(data_rec.values())\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(11, 3), sharey=True)\n",
        "\n",
        "axs[0].plot(names_acc, values_acc, label='accuracy')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].plot(names_prec, values_prec, label='precision')\n",
        "axs[1].legend(('precision for target=1', 'precision for target=0'))\n",
        "\n",
        "axs[2].plot(names_rec, values_rec, label='recall')\n",
        "axs[2].legend(('recall for target=1', 'recall for target=0'))\n",
        "\n",
        "fig.suptitle('Accuracy, precision and recall for multiple value of train/test split treshold')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/Samuel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": [
              "Text(0.5, 0.98, 'Accuracy, precision and recall for multiple value of train/test split treshold')"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:26:01.393Z",
          "iopub.execute_input": "2020-05-12T20:26:01.408Z",
          "iopub.status.idle": "2020-05-12T20:28:11.436Z",
          "shell.execute_reply": "2020-05-12T20:28:11.718Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('From those graphs, we can see that the optimal train/test split treshold seems to be around 0.3.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From those graphs, we can see that the optimal train/test split treshold seems to be around 0.3.\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:28:11.493Z",
          "iopub.execute_input": "2020-05-12T20:28:11.554Z",
          "iopub.status.idle": "2020-05-12T20:28:11.621Z",
          "shell.execute_reply": "2020-05-12T20:28:11.775Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the model on the testing dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=72)\n",
        "\n",
        "X_test = test['text']\n",
        "\n",
        "\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "predicted = pipe.predict(X_test)\n",
        "\n",
        "test['prediction'] = predicted\n",
        "\n",
        "test[['text', 'prediction']].head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": [
              "                                                text  prediction\n",
              "0                 Just happened a terrible car crash           1\n",
              "1  Heard about #earthquake is different cities, s...           1\n",
              "2  there is a forest fire at spot pond, geese are...           1\n",
              "3           Apocalypse lighting. #Spokane #wildfires           0\n",
              "4      Typhoon Soudelor kills 28 in China and Taiwan           1"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:28:52.723Z",
          "iopub.execute_input": "2020-05-12T20:28:52.738Z",
          "iopub.status.idle": "2020-05-12T20:28:54.704Z",
          "shell.execute_reply": "2020-05-12T20:28:54.734Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create submission file"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sub=pd.read_csv('../data/sample_submission.csv')\n",
        "\n",
        "sub=pd.DataFrame({'id':sample_sub['id'].values.tolist(),'target': predicted})\n",
        "sub.to_csv('../data/submission.csv',index=False)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T20:28:57.164Z",
          "iopub.execute_input": "2020-05-12T20:28:57.177Z",
          "iopub.status.idle": "2020-05-12T20:28:57.199Z",
          "shell.execute_reply": "2020-05-12T20:28:57.222Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural networks\n",
        "### To be continued"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.23.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}